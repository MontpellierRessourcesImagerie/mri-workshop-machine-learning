{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14SvEOwMpFq5Kb9AcQCmGhNDIHqvolkaF","timestamp":1668792026706}],"authorship_tag":"ABX9TyPDTr7scxs2hq5lC2vTYCFX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Nuclei segmentation using StarDist\n","\n","With this example, we will illustrate how StarDist can be easily trained to segment 2D nuclei images. \n","\n","Data were kindly provided by Marcelo NÃ¶llmann, from the Centre of Biologie Structurale, Montpellier (FRANCE). \n","\n","This notebook was directly inspired from the existing notebooks created by Uwe Schmidt (https://github.com/stardist/stardist)."],"metadata":{"id":"6gqVXj7C9HFF"}},{"cell_type":"markdown","source":["## I - packages installation: \n","Installation of the specific packages for SytarDist: \n","- csbdeep is a library of tools dedicated for DL and handling / processing the data\n","- stardist is the library for network\n","- augmend is a package for image augmentation"],"metadata":{"id":"X2cqHN1T92n4"}},{"cell_type":"code","source":["!pip install csbdeep\n","!pip install stardist\n","!pip install git+https://github.com/stardist/augmend.git"],"metadata":{"id":"AZlNQfGNvK0-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7E-gRI_u0uZ"},"outputs":[],"source":["from __future__ import print_function, unicode_literals, absolute_import, division\n","\n","## Libraries for files management and mathematical operations\n","\n","import numpy as np\n","import time, os, sys\n","import numpy as np\n","from tqdm import tqdm # for displaying a progression bar\n","from glob import glob # recursive search of files or folder based on a specific pattern\n","# import wget\n","from urllib.parse import urlparse\n","\n","## Libraries for displaying images and plotting graphs \n","\n","import matplotlib\n","matplotlib.rcParams[\"image.interpolation\"] = None\n","matplotlib.rcParams['figure.dpi'] = 300\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","## Libraries for image management and manipulaption\n","\n","from tifffile import imread, imwrite # handle tif file format\n","import skimage.io\n","\n","## Specific libraries for Deep Learning and image segmentation\n","\n","from csbdeep.utils import Path, normalize\n","from csbdeep.io import save_tiff_imagej_compatible\n","\n","from augmend import Augmend, FlipRot90, Elastic, Identity, IntensityScaleShift, AdditiveNoise, Scale\n","\n","from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n","from stardist import calculate_extents, gputools_available, Rays_GoldenSpiral\n","from stardist import fill_label_holes, relabel_image_stardist, random_label_cmap\n","from stardist.matching import matching, matching_dataset\n","\n","np.random.seed(6)\n","lbl_cmap = random_label_cmap()\n","print('importing libraries done')"]},{"cell_type":"markdown","source":["## I - Data importation\n","\n","The data are 2d 16bit images saved in the tif format on a google drive. All images are paired :\n","\n","- one raw image\n","- one labelled image where each nuclei are instanciated, meaning that each single nuclei is assigned a unique positive pixel value. By default the background is set to 0. "],"metadata":{"id":"BkyaDKXw-ogH"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0zQ5hyn3wyMg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["StarDist exists in 2d or 3d. For this example, we will work with 2d images but the principle is the same when working with 3d images.\n","The parameters for the two options are describe below. Note that for this example, the data have already been splitted into two data sets: \n","- one for the training\n","- one for testing"],"metadata":{"id":"Glwe2c_C_MNj"}},{"cell_type":"code","source":["option = '2d'\n","\n","if option == '3d':\n","    data_training = ...\n","    data_testing = ...\n","    dest_path = ...\n","    model_name = ...\n","    n_channel = 1\n","    axis_norm = (0,1,2)\n","    n_dim = 3\n","    axis_augmentation = (1,2)\n","else:\n","    data_training = \"/content/drive/MyDrive/Deep_learning_formation_MRI/Doc_JB_2022/Notebooks for workshop /Data/Nuclei_segmentation/training_data\"\n","    data_testing = \"/content/drive/MyDrive/Deep_learning_formation_MRI/Doc_JB_2022/Notebooks for workshop /Data/Nuclei_segmentation/testing_data\"\n","    dest_path = \"/content/drive/MyDrive/Deep_learning_formation_MRI/Doc_JB_2022/Notebooks for workshop /Data/Nuclei_segmentation\"\n","    model_name = 'stardist_embryos_2d_2022_03_21'\n","    n_channel = 1\n","    axis_norm = (0,1)\n","    n_dim = 2\n","    axis_augmentation = (0,1)\n","    IMG_HEIGHT = 256\n","    IMG_WIDTH = 256\n","\n","# Depending on the selected option, load the StarDist model accordingly\n","if option == '3d':\n","    from stardist.models import StarDist3D, Config3D\n","else:\n","    from stardist.models import Config2D, StarDist2D, StarDistData2D"],"metadata":{"id":"CYRksHeEwnj_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the data using the get_data method."],"metadata":{"id":"vlTpj2Z7CwCU"}},{"cell_type":"code","source":["def get_data(file_list):\n","    file_list = sorted(file_list)\n","    im_list = list(map(imread,file_list))\n","    return im_list"],"metadata":{"id":"M0YE3Xptxcr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the raw images for the training\n","X = get_data(glob(os.path.join(data_training, 'raw', '*.tif')))\n","print(f'number of training raw images found : {len(X)}')\n","\n","# load the label images\n","Y = get_data(glob(os.path.join(data_training, 'label_class', '*.tif')))\n","print(f'number of training label images found : {len(Y)}')\n","\n","# load the raw images for the training\n","X_test = get_data( glob(os.path.join(data_testing, 'raw', '*.tif')))\n","print(f'number of training raw images found : {len(X_test)}')\n","\n","# load the label images\n","Y_test = get_data(glob(os.path.join(data_testing, 'label_class', '*.tif')))\n","print(f'number of training label images found : {len(Y_test)}')"],"metadata":{"id":"NziQ3vKcxSZY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## II - Data visualization and analysis:\n","\n","Below an example of a pair of raw / labelled images is displayed. Since StarDist is performing instanciation, each single nuclei is assigned a unique positive pixel value. "],"metadata":{"id":"p-9G3oe7DIX1"}},{"cell_type":"code","source":["# select an image from the loaded data\n","n_im = np.random.randint(0, len(X)-1)\n","raw, lbl = X[n_im], Y[n_im]\n","\n","if option == '3d':\n","    # plot the xy-MIP of the raw image and its associated label image\n","    plt.figure(figsize=(16,10))\n","    plt.subplot(121); plt.imshow(np.max(raw,axis=0),cmap='gray')\n","    plt.axis('off'); plt.title('MIP of raw image (XY slice)')\n","    plt.subplot(122); plt.imshow(np.max(lbl, axis=0),cmap=lbl_cmap)\n","    plt.axis('off'); plt.title('GT labels (XY slice)')\n","\n","    # plot the xz-MIP of the raw image and its associated label image\n","    plt.figure(figsize=(16,10))\n","    plt.subplot(121); plt.imshow(np.max(raw,axis=1),cmap='gray')\n","    plt.axis('off'); plt.title('MIP of raw image (XZ slice)')\n","    plt.subplot(122); plt.imshow(np.max(lbl, axis=1),cmap=lbl_cmap)\n","    plt.axis('off'); plt.title('GT labels (XZ slice)')\n","\n","else:\n","    # plot a raw image and its associated label\n","    plt.figure(figsize=(16,10))\n","    plt.subplot(121); plt.imshow(raw,cmap='gray')\n","    plt.axis('off'); plt.title('raw image')\n","    plt.subplot(122); plt.imshow(lbl,cmap=lbl_cmap)\n","    plt.axis('off'); plt.title('GT labels')\n","\n","None;"],"metadata":{"id":"9pkDoS-AyyRH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Normalize the raw data. "],"metadata":{"id":"0sQ8tCKSJso9"}},{"cell_type":"code","source":["X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n","# Y = [fill_label_holes(y) for y in tqdm(Y)]\n","\n","X_test = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X_test)]\n","# Y_test = [fill_label_holes(y) for y in tqdm(Y_test)]"],"metadata":{"id":"0KY5y1Bz6mZm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compute the anisotropy of all the labelled objects. This is important for StarDist since the segmentation is based on the reconstruction of star-convex polygons defined by a specific set of rays. For isotropy objects, the number of rays can be low.  "],"metadata":{"id":"zuEjAZKOMoE3"}},{"cell_type":"code","source":["# compute the anisotropy of the label objects\n","extents = calculate_extents(Y)\n","anisotropy = tuple(np.max(extents) / extents)\n","print('Empirical anisotropy of labeled objects = %s' % str(anisotropy))\n","\n","# compute the min dimensions of the training set\n","im_dim = np.zeros((len(X), n_dim))\n","for n,im in enumerate(X):\n","    im_dim[n,:] = im.shape\n","print(f'The smallest dimensions of the training set are : {np.min(im_dim, axis=0)}')\n","\n","# compute the median size of the nuclei\n","median_size = calculate_extents(Y, np.median)\n","print(f\"Median object size:      {median_size}\")"],"metadata":{"id":"S_Jcf5_2_DQw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Below is an illustration of the effect of the number of rays on the reconstruction of the nuclei."],"metadata":{"id":"r3YpkJJPPS2D"}},{"cell_type":"code","source":["# defines the number of rays to test for the reconstruction\n","n_rays = [2**i for i in range(2,8)]\n","\n","# select an image from the loaded data\n","n_im = np.random.randint(0, len(X)-1)\n","raw, lbl = X[n_im], Y[n_im]\n","\n","# plot the reconstruction\n","ig, ax = plt.subplots(2,3, figsize=(16,11))\n","for a,r in zip(ax.flat,n_rays):\n","    a.imshow(relabel_image_stardist(lbl, n_rays=r), cmap=lbl_cmap)\n","    a.set_title('Reconstructed (%d rays)' % r)\n","    a.axis('off')\n","plt.tight_layout();"],"metadata":{"id":"a3h3dUMkOcQF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## III- Defining the parameters for StarDist\n","\n","Below the parameters for the network are defined. The number of rays as well the number of epochs, the batch size, the architecture of the network,  etc."],"metadata":{"id":"6ulw5dKnP3P0"}},{"cell_type":"code","source":["# 96 is a good default choice for anisotropic 3D data (see 1_data.ipynb) - 32 is usually fine for anisotropic 2D data\n","if option == '3d':\n","    n_rays = 96\n","    train_patch_size = (28,128,128)\n","else:\n","    n_rays = 32\n","    train_patch_size = (128,128)\n","\n","# Use OpenCL-based computations for data generator during training (requires 'gputools')\n","use_gpu = True and gputools_available()\n","\n","# Predict on subsampled grid for increased efficiency and larger field of view\n","grid = tuple(1 if a > 1.5 else 4 for a in anisotropy)\n","\n","if option == '3d':\n","    \n","    # Use rays on a Fibonacci lattice adjusted for measured anisotropy of the training data\n","    rays = Rays_GoldenSpiral(n_rays, anisotropy=anisotropy)\n","    conf = Config3D (\n","        rays             = rays,\n","        grid             = grid,\n","        anisotropy       = anisotropy,\n","        use_gpu          = use_gpu,\n","        n_channel_in     = 1,\n","        # adjust for your data below (make patch size as large as possible)\n","        train_patch_size = train_patch_size,\n","        train_batch_size = 2,\n","        backbone = 'unet',\n","        train_epochs = 1,\n","        train_steps_per_epoch = 100\n","    )\n","else:\n","    conf = Config2D (\n","        n_rays             = n_rays,\n","        grid             = grid,\n","        use_gpu          = use_gpu,\n","        n_channel_in     = 1,\n","        # adjust for your data below (make patch size as large as possible)\n","        train_patch_size = train_patch_size,\n","        train_batch_size = 2,\n","        backbone = 'unet', #'resnet'\n","        train_epochs = 50,\n","        train_steps_per_epoch = 50\n","    )\n","vars(conf)"],"metadata":{"id":"rL_9bjjs6q9S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compile the model according to the parameters indicated above :"],"metadata":{"id":"lkz1cNXyQPQC"}},{"cell_type":"code","source":["# create the folder if it does not exist yet\n","if not os.path.exists(dest_path):\n","    os.mkdir(dest_path)\n","    print(f\"folder {dest_path} created!\")\n","\n","# based on the parameters defined above, create the StarDist model\n","model_folder = os.path.join(dest_path, model_name)\n","if option == '3d':\n","    model = StarDist3D(conf, name=model_name, basedir=model_folder)\n","else:\n","    model = StarDist2D(conf, name=model_name, basedir=model_folder)"],"metadata":{"id":"FogUuCtB_Zt1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compute the median size of the nuclei and check if the neural network has a large enough field of view to see up to the boundary of most objects.\n"],"metadata":{"id":"A-J-MdboQoKB"}},{"cell_type":"code","source":["median_size = calculate_extents(Y, np.median)\n","if option == '3d':\n","    fov = np.array(model._axes_tile_overlap('ZYX'))\n","else:\n","    fov = np.array(model._axes_tile_overlap('YX'))\n","    \n","print(f\"median object size:      {median_size}\")\n","print(f\"network field of view :  {fov}\")\n","if any(median_size > fov):\n","    print(\"WARNING: median object size larger than field of view of the neural network.\")"],"metadata":{"id":"SYWqt0Dc_xgK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Add data augmentation."],"metadata":{"id":"ncF_zxG9V9GO"}},{"cell_type":"code","source":["elastic_kwargs = dict(axis=axis_augmentation, amount=10, use_gpu=model.config.use_gpu)\n","#scale_kwargs = dict(axis=1, amount=1.5, use_gpu=model.config.use_gpu)\n","aug = Augmend()\n","#aug.add([Scale(order=0,**scale_kwargs),Scale(order=0,**scale_kwargs)], probability=0.25)\n","aug.add([FlipRot90(axis=axis_augmentation),FlipRot90(axis=axis_augmentation)])\n","aug.add([Elastic(order=0,**elastic_kwargs),Elastic(order=0,**elastic_kwargs)], probability=0.5)\n","aug.add([IntensityScaleShift(scale=(.6,2),shift=(-.2,.2)),Identity()])\n","aug.add([AdditiveNoise(sigma=(0.05,0.05)),Identity()], probability=0.25)\n","\n","def augmenter(x,y):\n","    return aug([x,y])"],"metadata":{"id":"vh60DB53_2dQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Launch the training : "],"metadata":{"id":"AkKFWV-nWAoZ"}},{"cell_type":"code","source":["model.train(X, Y, validation_data=(X_test,Y_test), augmenter=augmenter)"],"metadata":{"id":"8Fza0gLH_4No"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## IV- Reconstruction and visualization of the results\n","\n","Finalization of the reconstruction and display the results."],"metadata":{"id":"IDJOs4edWisK"}},{"cell_type":"code","source":["model.optimize_thresholds(X_test, Y_test)"],"metadata":{"id":"cTt-eR87COxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# using the newly trained model, calculate the segmentation prediction using the test images\n","Y_test_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n","              for x in tqdm(X_test)]"],"metadata":{"id":"nhgODjgFCSeR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_img_label(img, lbl, img_title=\"image (XY slice)\", lbl_title=\"label (XY slice)\", **kwargs):\n","    \n","    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n","    if len(img.shape) == 3:\n","        im = ai.imshow(np.max(img, axis=0), cmap='gray', clim=(0,1))\n","    else:\n","        im = ai.imshow(img, cmap='gray', clim=(0,1))\n","    ai.set_title(img_title)    \n","    fig.colorbar(im, ax=ai)\n","    if len(img.shape) == 3:\n","        al.imshow(np.max(lbl, axis=0), cmap=lbl_cmap)\n","    else:\n","        al.imshow(lbl, cmap=lbl_cmap)\n","    al.set_title(lbl_title)\n","    plt.tight_layout()\n","\n","n_image = np.random.randint(0, len(X_test)-1)\n","plot_img_label(X_test[n_image],Y_test[n_image], lbl_title=\"label GT (XY slice)\")\n","plot_img_label(X_test[n_image],Y_test_pred[n_image], lbl_title=\"label Pred (XY slice)\")"],"metadata":{"id":"4bWx2eUHCX2g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n","stats = [matching_dataset(Y_test, Y_test_pred, thresh=t, show_progress=False) for t in tqdm(taus)]\n","\n","fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n","\n","for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'):\n","    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n","ax1.set_xlabel(r'IoU threshold $\\tau$')\n","ax1.set_ylabel('Metric value')\n","ax1.grid()\n","ax1.legend()\n","\n","for m in ('fp', 'tp', 'fn'):\n","    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n","ax2.set_xlabel(r'IoU threshold $\\tau$')\n","ax2.set_ylabel('Number #')\n","ax2.grid()\n","ax2.legend();"],"metadata":{"id":"67804R-fCrt3"},"execution_count":null,"outputs":[]}]}