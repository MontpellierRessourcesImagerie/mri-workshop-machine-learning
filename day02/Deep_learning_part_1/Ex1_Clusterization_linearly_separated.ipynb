{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fDffIYZcPeb"
      },
      "source": [
        "# First step : a single neuron network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkxGJmDWcPef"
      },
      "source": [
        "This example is a first example of artificial neural network. For now, one single neuron will be used to classify two classes of dots in the xy plane, according to their 2D \n",
        "spatial coordinates.\n",
        "\n",
        "Here we define the training data set where the two classes are simply defined by points above or below a straight line:\n",
        "\n",
        "$(Y<aX+b)$ \n",
        "\n",
        "or \n",
        "\n",
        "$(Y>aX+b)$.\n",
        "\n",
        "The size (i.e. the number of xy points) of the Training data set can be set. On top of it a Validation data set and a Testing data set are also defined. The xy position of the points is defined randomly, and each point belongs to one class, determined by its position with respect to the line, and indicated by its color."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC0bkj3acPeh"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "    \n",
        "def Training_set_linear(a,b,Ntrain,Nval,Ntest):\n",
        "    \n",
        "    n = 0\n",
        "    N = Ntrain+Nval+Ntest\n",
        "    Data = np.zeros([N,2])\n",
        "    Labels = np.zeros([N,1])\n",
        "      \n",
        "    for n in range(0,N):\n",
        "        x = random.uniform(-1, 1)\n",
        "        y = random.uniform(-1, 1)\n",
        "        Data[n,0] = x\n",
        "        Data[n,1] = y\n",
        "        \n",
        "        if y < a*x+b :\n",
        "            Labels[n,0] = 1\n",
        "        else : \n",
        "            Labels[n,0] = 0\n",
        "\n",
        "    Training_data = Data[:Ntrain,]\n",
        "    Training_label = Labels[:Ntrain,]\n",
        "    Validation_data = Data[Ntrain+1:Ntrain+Nval,]\n",
        "    Validation_label = Labels[Ntrain+1:Ntrain+Nval,]\n",
        "    Testing_data = Data[Ntrain+Nval+1:N:,]\n",
        "    Testing_label = Labels[Ntrain+Nval+1:N:,]\n",
        "        \n",
        "    return Training_data, Testing_data, Validation_data, Training_label, Validation_label, Testing_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J39vdBLYcPep"
      },
      "source": [
        "The actual training/validation/testing sets are defined below. Try different Ntrain (100, 500, 1000, ...), the number of training points. You will see why \"deep learning\" requires lots of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUMV9J_kcPeq"
      },
      "source": [
        "a = 0.5\n",
        "b = 0.1\n",
        "Ntrain = 100 \n",
        "Nval = 50\n",
        "Ntest = 50\n",
        "    \n",
        "Training_data, Testing_data, Validation_data, Training_label, Validation_label, Testing_label = Training_set_linear(a,b,Ntrain,Nval,Ntest) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYpe5hvMrl-c"
      },
      "source": [
        "The training set is then plot using two different colors\n",
        "to distinguish the two classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zNEW_y9rXZr"
      },
      "source": [
        "Idx_class_0 = Training_label==0\n",
        "Idx_class_1 = Training_label==1\n",
        "\n",
        "X0 = Training_data[Idx_class_0[:,0],0]\n",
        "Y0 = Training_data[Idx_class_0[:,0],1]\n",
        "X1 = Training_data[Idx_class_1[:,0],0]\n",
        "Y1 = Training_data[Idx_class_1[:,0],1]\n",
        "\n",
        "X = np.array([-1,1])\n",
        "Y = a*X + b  \n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6,6) # Make the figures a bit bigger\n",
        "plt.plot(X0, Y0, 'r.', markersize=10)\n",
        "plt.plot(X1, Y1, 'b.',  markersize=10)\n",
        "plt.plot(X,Y,'--k')\n",
        "plt.xlabel('X train', fontsize=15)\n",
        "plt.ylabel('Y train', fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06RWPickcPew"
      },
      "source": [
        "Define the architecture of the model. Here only one neuron is used with two inputs : the X and Y coordinates of each point of the train set. \n",
        "Since we are working with two classes, the activation function is \"`sigmoid`\", so the output (in 0,1)  will be the probability of the point to belong to one class.\n",
        "The loss function compares the model output with the expected output, and `binary_crossentropy` is used when classifing only two classes. In the end the distinction between the two classes will be made on the base of whether the output will be below or above 0.5 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dPKuZ9WcPex"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "  Dense(1,activation='sigmoid', input_shape=(2,))\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R73avK1cPe1"
      },
      "source": [
        "Here we train the model. We send a batch of points to the model, which gives its predictions, and then corrects its weights trying to minimize the loss function. \n",
        "When all the training points have been used, an epoch is done, and a new epoch can start again. The number of epochs can be defined below. The results at each iteraction\n",
        "are saved in order to compare the accuracy calculated for the training set and for the validation set. These data are saved in the variable \"history\", which will be used later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tykToIAQcPe2"
      },
      "source": [
        "history = model.fit(Training_data,\n",
        "                    Training_label,\n",
        "                    epochs = 150,\n",
        "                    validation_data = (Validation_data, Validation_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAOXUQVFcPe7"
      },
      "source": [
        "Once trained, the accuracy of the model is calculated using the testing set of data. Here we plot the predictions of the model over testing points it has never seen before\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znr10eqicPe9"
      },
      "source": [
        "Results = model.predict(Testing_data)\n",
        "\n",
        "Idx_class_0 = Results < 0.5\n",
        "Idx_class_1 = Results >= 0.5\n",
        "\n",
        "X0 = Testing_data[Idx_class_0[:,0],0]\n",
        "Y0 = Testing_data[Idx_class_0[:,0],1]\n",
        "X1 = Testing_data[Idx_class_1[:,0],0]\n",
        "Y1 = Testing_data[Idx_class_1[:,0],1]\n",
        "\n",
        "X = np.array([-1,1])\n",
        "Y = a*X + b        \n",
        "        \n",
        "plt.rcParams['figure.figsize'] = (6,6) # Make the figures a bit bigger\n",
        "plt.plot(X0, Y0, 'r.', markersize=10)\n",
        "plt.plot(X1, Y1, 'b.',  markersize=10)\n",
        "plt.plot(X,Y,'--k')\n",
        "plt.xlabel('X test', fontsize=15)\n",
        "plt.ylabel('Y test', fontsize=15)\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khhbZWAacPfB"
      },
      "source": [
        "In the same way, using the \"model.evaluate\" function you can test the accuracy of the model when working on the testing set. The second number returns the average accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcJUPTS8cPfC"
      },
      "source": [
        "Predication_accuracy = model.evaluate(Testing_data, Testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YQrKlqGcPfF"
      },
      "source": [
        "Below the accuracy for the training and validation sets are plotted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIsUDPO8cPfG"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "n = len(acc_values)\n",
        "epochs = range(1, n+1)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs', fontsize=15)\n",
        "plt.ylabel('Accuracy', fontsize=15)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fT953nLcPfK"
      },
      "source": [
        "Below the validation loss for the training and validation sets are plotted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdBmBP1QcPfL"
      },
      "source": [
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "plt.plot(epochs, loss_values, '-bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs', fontsize=15)\n",
        "plt.ylabel('Loss', fontsize=15)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-0b5Osbr9bu"
      },
      "source": [
        "Here we define a test set on a regular grid, so we can see more clearly how the real line that separates the two classes comapres with the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy1XFYsmzJgx"
      },
      "source": [
        "x = np.linspace(-1, 1, 50)\n",
        "y = np.linspace(-1, 1, 50)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "X = X.flatten()\n",
        "Y = Y.flatten()\n",
        "\n",
        "Test = np.vstack((X,Y))\n",
        "Test = np.transpose(Test)\n",
        "Results = model.predict(Test)\n",
        "\n",
        "Idx_class_0 = Results<0.5\n",
        "Idx_class_1 = Results>=0.5\n",
        "\n",
        "X0 = Test[Idx_class_0[:,0],0]\n",
        "Y0 = Test[Idx_class_0[:,0],1]\n",
        "X1 = Test[Idx_class_1[:,0],0]\n",
        "Y1 = Test[Idx_class_1[:,0],1]\n",
        "\n",
        "X = np.array([-1,1])\n",
        "Y = a*X + b        \n",
        "        \n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "plt.plot(X0, Y0, 'r.')\n",
        "plt.plot(X1, Y1, 'b.')\n",
        "plt.plot(X,Y,'--k')\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVg3-sSM2dfl"
      },
      "source": [
        "Now go back and change the **number of points** in the training set, and see how the model performs with more or less training data.\n",
        "Also, change and see the effects of the **batch_size** in the training fit function, and of the **number of epochs**. Is the separation between the blue and red points always a straight line?"
      ]
    }
  ]
}