{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step : a single neuron network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is a first example of artificial neural network. One single neuron will be used to \n",
    "classify two classes of dots according to their 2D spatial coordinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of a training data where the two classes are simply defined by Y<aX+b or Y>aX+b. The size of the \n",
    "training data set is 500. On top of it a Validation data set and a Testing data set are also defined, both of them\n",
    "being of size 200. All points are defined randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "def Training_set_linear(a,b,N):\n",
    "    \n",
    "    n = 0\n",
    "    Data = np.zeros([N+400,2])\n",
    "    Labels = np.zeros([N+400,1])\n",
    "      \n",
    "    for n in range(0,N+400):\n",
    "        x = random.uniform(-1, 1)\n",
    "        y = random.uniform(-1, 1)\n",
    "        Data[n,0] = x\n",
    "        Data[n,1] = y\n",
    "        \n",
    "        if y < a*x+b :\n",
    "            Labels[n,0] = 1\n",
    "        else : \n",
    "            Labels[n,0] = 0\n",
    "\n",
    "    Training_data = Data[:N,]\n",
    "    Training_label = Labels[:N,]\n",
    "    Validation_data = Data[N:N+200,]\n",
    "    Validation_label = Labels[N:N+200,]\n",
    "    Testing_data = Data[N+200:,]\n",
    "    Testing_label = Labels[N+200:,]\n",
    "        \n",
    "    return Training_data, Testing_data, Validation_data, Training_label, Validation_label, Testing_label\n",
    "\n",
    "def Training_set_clusters(N):\n",
    "    \n",
    "    n = 0\n",
    "    Data = np.zeros([N+400,2])\n",
    "    Labels = np.zeros([N+400,1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training/validation/testing sets are defined below. The training set is then plot using two different colors\n",
    "to distinguish the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.5;\n",
    "b = 0.1;\n",
    "N = 500;\n",
    "    \n",
    "Training_data, Testing_data, Validation_data, Training_label,Validation_label, Testing_label = Training_set_linear(a,b,N) \n",
    "    \n",
    "X0 = []\n",
    "X1 = []\n",
    "Y0 = []\n",
    "Y1 = []\n",
    "for n in range(0,N):\n",
    "    x = Training_data[n,0]\n",
    "    if Training_label[n]==0:\n",
    "        X0.append(Training_data[n,0])\n",
    "        Y0.append(Training_data[n,1])\n",
    "    else:\n",
    "        X1.append(Training_data[n,0])\n",
    "        Y1.append(Training_data[n,1])\n",
    "\n",
    "X = np.array([-1,1])\n",
    "Y = a*X + b  \n",
    "        \n",
    "plt.plot(X0, Y0, 'r.')\n",
    "plt.plot(X1, Y1, 'b.')\n",
    "plt.plot(X,Y,'--k')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the architecture of the model. Here only one neuron is used with two inputs : the X and Y coordinates. \n",
    "Since we are working with two classes, the activation function is \"sigmoid\" and the loss function \"binary cross-\n",
    "entropy\". In the end the distinction between the two classes will be made on the base of whether the output will be\n",
    "below or above 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1,activation='sigmoid', input_shape=(2,)))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model. The number of Epoch is defined below. The results at each iteraction\n",
    "are saved in order to compare the accuracy calculated for the training set and for the validation set. These data are\n",
    "saved in the variable \"history\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(Training_data,\n",
    "                    Training_label,\n",
    "                    epochs = 50,\n",
    "                    validation_data = (Validation_data, Validation_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is calculated using the testing set of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = model.predict(Testing_data)\n",
    "Length = len(Results)\n",
    "\n",
    "X0 = []\n",
    "X1 = []\n",
    "Y0 = []\n",
    "Y1 = []\n",
    "for n in range(0,Length):\n",
    "\n",
    "    if Results[n]<=0.5:\n",
    "        X0.append(Testing_data[n,0])\n",
    "        Y0.append(Testing_data[n,1])\n",
    "    else:\n",
    "        X1.append(Testing_data[n,0])\n",
    "        Y1.append(Testing_data[n,1])\n",
    "\n",
    "X = np.array([-1,1])\n",
    "Y = a*X + b        \n",
    "        \n",
    "plt.plot(X0, Y0, 'r.')\n",
    "plt.plot(X1, Y1, 'b.')\n",
    "plt.plot(X,Y,'--k')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, using the \"model.evaluate\" function you can test the accuracy of the model when working on the testing set. The second number returns the average accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predication_accuracy = model.evaluate(Testing_data, Testing_label)\n",
    "print(Predication_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the accuracy for the training and validation sets are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "n = len(acc_values)\n",
    "epochs = range(1, n+1)\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the validation loss for the training and validation sets are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "plt.plot(epochs, loss_values, '-bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
