{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First example of a convNet\n",
    "\n",
    "With this example we will understand how to build a convolution neural network and apply it to hand-written digit classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries we will need to define the DL network and load the MNIST set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images_all, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the shape of the images from a 2D array to a tensor. The labels are also changed from digit to\n",
    "categorical. Finally the data are normalized and a validation set is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_all = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "train_images = train_images_all[0:20000]\n",
    "validation_images = train_images_all[50000:60000]\n",
    "train_labels = train_labels_all[0:20000]\n",
    "validation_labels = train_labels_all[50000:60000]\n",
    "\n",
    "train_images = train_images.reshape((20000,28,28,1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "validation_images = validation_images.reshape((10000,28,28,1))\n",
    "validation_images = validation_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28,28,1))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, plot the nth image of the training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "digit = train_images_all[n]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "label = train_labels[n]\n",
    "print('The associated label for this image is ', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the convNet applied to digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=64,\n",
    "                   validation_data = (validation_images, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy of the model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the accuracy for the training and validation sets are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print( history_dict.keys() )\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "n = len(acc_values)\n",
    "epochs = range(1, n+1)\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show what and how the network is learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers[:6]]\n",
    "activation_model = models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "\n",
    "activations = activation_model.predict(test_images)\n",
    "first_layer_activation = activations[1]\n",
    "print(first_layer_activation.shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer_names = []\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer_names.append(layer.name)\n",
    "    \n",
    "images_per_row = 8\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    \n",
    "    size = layer_activation.shape[1]\n",
    "    \n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    \n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[1,:,:,col * images_per_row + row]\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col+1) * size,\n",
    "                        row * size : (row+1) * size] = channel_image\n",
    "            \n",
    "scale = 1. / size\n",
    "plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                   scale * display_grid.shape[0]))\n",
    "plt.title(layer_name)\n",
    "plt.grid(False)\n",
    "plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
